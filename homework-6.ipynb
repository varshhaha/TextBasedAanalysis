{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09da671",
   "metadata": {},
   "source": [
    "# TEXT1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d11ce",
   "metadata": {},
   "source": [
    "# IMPORTING THE NEEDED MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b215520",
   "metadata": {},
   "source": [
    "# Open the file and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24de547",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open( \"C:\\\\Users\\\\varsh\\\\Downloads\\\\German.txt\" , \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58666097",
   "metadata": {},
   "source": [
    "# Our data: a list of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ac8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentences are \", sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf4d621",
   "metadata": {},
   "source": [
    "# Function to calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d64d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity (sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "  # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9af78",
   "metadata": {},
   "source": [
    "# Create the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5766edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e62b736",
   "metadata": {},
   "source": [
    "# Similarity matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00381070",
   "metadata": {},
   "source": [
    "# Get the pagerank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bdcc6b",
   "metadata": {},
   "source": [
    "# Sort sentences by pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort sentences by pagerank\n",
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",\n",
    "ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41786a",
   "metadata": {},
   "source": [
    "# Pick the top “n” sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b28470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ef4c0",
   "metadata": {},
   "source": [
    "# Finish off by printing summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42dcad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4ecb9",
   "metadata": {},
   "source": [
    "# TEXT2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c65f6",
   "metadata": {},
   "source": [
    "# IMPORTING THE NEEDED MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290dbe5",
   "metadata": {},
   "source": [
    "# Open the file and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d5c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open( \"C:\\\\Users\\\\varsh\\\\Downloads\\\\jj.txt\" , \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42081ec",
   "metadata": {},
   "source": [
    "# Our data: a list of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentences are \", sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3492b0",
   "metadata": {},
   "source": [
    "# FUNCTION TO DEFINE SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity (sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "  # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1add3",
   "metadata": {},
   "source": [
    "# Create the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2a8b4",
   "metadata": {},
   "source": [
    "# Similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8378f",
   "metadata": {},
   "source": [
    "# Get the pagerank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a61f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_similarity_graph =nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0845a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5e83f",
   "metadata": {},
   "source": [
    "# Sort sentences by pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46625509",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",\n",
    "ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e69418",
   "metadata": {},
   "source": [
    "# Pick the top \"n\" sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4dfcb2",
   "metadata": {},
   "source": [
    "# Finishing off by printing summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0712ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe752a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687d5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e750b6",
   "metadata": {},
   "source": [
    "# Text-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b7cf98",
   "metadata": {},
   "source": [
    "# IMPORTING THE NEEDED MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbede1d2",
   "metadata": {},
   "source": [
    "# Open the file and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f91ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open( \"C:\\\\Users\\\\varsh\\\\Downloads\\\\Spanish.txt\" , \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d40a40",
   "metadata": {},
   "source": [
    "# Our data: a list of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcb7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee6c1a",
   "metadata": {},
   "source": [
    "# Function to calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd064e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity (sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "  # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fe063",
   "metadata": {},
   "source": [
    "# Create the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6564570",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8f32c0",
   "metadata": {},
   "source": [
    "# Similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8cc5cf",
   "metadata": {},
   "source": [
    "# Get pagerank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c3cfe",
   "metadata": {},
   "source": [
    "# sort sentences by pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba62f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",\n",
    "ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e51c56",
   "metadata": {},
   "source": [
    "# Pick the top \"n\" sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d582b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816bdeb0",
   "metadata": {},
   "source": [
    "# Finishing off by printing summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c677ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
