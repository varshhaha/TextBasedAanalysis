{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d09da671",
   "metadata": {},
   "source": [
    "# TEXT1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d11ce",
   "metadata": {},
   "source": [
    "# IMPORTING THE NEEDED MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1caa6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b215520",
   "metadata": {},
   "source": [
    "# Open the file and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24de547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Herr und Frau Meyer fahren oft in die Berge\n",
      "Berge gibt es in Deutschland, Ã–sterreich, Italien und der Schweiz\n",
      "Ihr Reiseziel ist in diesem Jahr die Schweiz\n",
      "Dort kann man viel wandern\n",
      "In einem Berghotel haben sie ein Zimmer gebucht.\n"
     ]
    }
   ],
   "source": [
    "file = open( \"C:\\\\Users\\\\varsh\\\\Downloads\\\\German.txt\" , \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58666097",
   "metadata": {},
   "source": [
    "# Our data: a list of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ac8304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['ï»¿Herr', 'und', 'Frau', 'Meyer', 'fahren', 'oft', 'in', 'die', 'Berge'], ['Berge', 'gibt', 'es', 'in', 'Deutschland,', 'Ã–sterreich,', 'Italien', 'und', 'der', 'Schweiz'], ['Ihr', 'Reiseziel', 'ist', 'in', 'diesem', 'Jahr', 'die', 'Schweiz'], ['Dort', 'kann', 'man', 'viel', 'wandern'], ['In', 'einem', 'Berghotel', 'haben', 'sie', 'ein', 'Zimmer', 'gebucht.']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf4d621",
   "metadata": {},
   "source": [
    "# Function to calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d64d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity (sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "  # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9af78",
   "metadata": {},
   "source": [
    "# Create the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5766edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.31622777 0.23570226 0.         0.11785113]\n",
      " [0.31622777 0.         0.2236068  0.         0.1118034 ]\n",
      " [0.23570226 0.2236068  0.         0.         0.125     ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.11785113 0.1118034  0.125      0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00381070",
   "metadata": {},
   "source": [
    "# Get the pagerank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64da3077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.2798301580999835, 1: 0.27285288315641704, 2: 0.24824364287595893, 3: 0.036144581616568326, 4: 0.16292873425107224}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bdcc6b",
   "metadata": {},
   "source": [
    "# Sort sentences by pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "338f4a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.2798301580999835, ['ï»¿Herr', 'und', 'Frau', 'Meyer', 'fahren', 'oft', 'in', 'die', 'Berge']), (0.27285288315641704, ['Berge', 'gibt', 'es', 'in', 'Deutschland,', 'Ã–sterreich,', 'Italien', 'und', 'der', 'Schweiz']), (0.24824364287595893, ['Ihr', 'Reiseziel', 'ist', 'in', 'diesem', 'Jahr', 'die', 'Schweiz']), (0.16292873425107224, ['In', 'einem', 'Berghotel', 'haben', 'sie', 'ein', 'Zimmer', 'gebucht.']), (0.036144581616568326, ['Dort', 'kann', 'man', 'viel', 'wandern'])]\n"
     ]
    }
   ],
   "source": [
    "#Sort sentences by pagerank\n",
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",\n",
    "ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41786a",
   "metadata": {},
   "source": [
    "# Pick the top “n” sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58b28470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 1\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "    summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ef4c0",
   "metadata": {},
   "source": [
    "# Finish off by printing summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a42dcad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " ï»¿Herr und Frau Meyer fahren oft in die Berge\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df4ecb9",
   "metadata": {},
   "source": [
    "# TEXT2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c65f6",
   "metadata": {},
   "source": [
    "# IMPORTING THE NEEDED MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9de6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5290dbe5",
   "metadata": {},
   "source": [
    "# Open the file and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d5c1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Ogni qual volta disegna suo papÃ  Giuseppe, ad esempio, usa sempre gli stessi colori: i capelli li fa in nero, la maglia Ã¨ azzurra e i pantaloni rigorosamente rossi\n",
      "Il papÃ  di Mattia non si veste ovviamente con colori cosÃ¬ sgargianti, ma a Mattia piace immaginarlo cosÃ¬.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open( \"C:\\\\Users\\\\varsh\\\\Downloads\\\\Italian.txt\" , \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42081ec",
   "metadata": {},
   "source": [
    "# Our data: a list of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "991d4609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['ï»¿Ogni', 'qual', 'volta', 'disegna', 'suo', 'papÃ\\xa0', 'Giuseppe,', 'ad', 'esempio,', 'usa', 'sempre', 'gli', 'stessi', 'colori:', 'i', 'capelli', 'li', 'fa', 'in', 'nero,', 'la', 'maglia', 'Ã¨', 'azzurra', 'e', 'i', 'pantaloni', 'rigorosamente', 'rossi'], ['Il', 'papÃ\\xa0', 'di', 'Mattia', 'non', 'si', 'veste', 'ovviamente', 'con', 'colori', 'cosÃ¬', 'sgargianti,', 'ma', 'a', 'Mattia', 'piace', 'immaginarlo', 'cosÃ¬.\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3492b0",
   "metadata": {},
   "source": [
    "# FUNCTION TO DEFINE SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "999e2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity (sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "  # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1add3",
   "metadata": {},
   "source": [
    "# Create the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f43b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2a8b4",
   "metadata": {},
   "source": [
    "# Similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "292c2ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.04016097]\n",
      " [0.04016097 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8378f",
   "metadata": {},
   "source": [
    "# Get the pagerank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "018a61f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_similarity_graph =nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac0845a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.5, 1: 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c5e83f",
   "metadata": {},
   "source": [
    "# Sort sentences by pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46625509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.5, ['ï»¿Ogni', 'qual', 'volta', 'disegna', 'suo', 'papÃ\\xa0', 'Giuseppe,', 'ad', 'esempio,', 'usa', 'sempre', 'gli', 'stessi', 'colori:', 'i', 'capelli', 'li', 'fa', 'in', 'nero,', 'la', 'maglia', 'Ã¨', 'azzurra', 'e', 'i', 'pantaloni', 'rigorosamente', 'rossi']), (0.5, ['Il', 'papÃ\\xa0', 'di', 'Mattia', 'non', 'si', 'veste', 'ovviamente', 'con', 'colori', 'cosÃ¬', 'sgargianti,', 'ma', 'a', 'Mattia', 'piace', 'immaginarlo', 'cosÃ¬.\\n'])]\n"
     ]
    }
   ],
   "source": [
    "ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",\n",
    "ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e69418",
   "metadata": {},
   "source": [
    "# Pick the top \"n\" sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cd7df58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 1\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "    summarize_text.append(\" \".join(ranked_sentence[i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4dfcb2",
   "metadata": {},
   "source": [
    "# Finishing off by printing summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f0712ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " ï»¿Ogni qual volta disegna suo papÃ  Giuseppe, ad esempio, usa sempre gli stessi colori: i capelli li fa in nero, la maglia Ã¨ azzurra e i pantaloni rigorosamente rossi\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe752a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687d5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e750b6",
   "metadata": {},
   "source": [
    "# Text-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b7cf98",
   "metadata": {},
   "source": [
    "# IMPORTING THE NEEDED MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a94be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbede1d2",
   "metadata": {},
   "source": [
    "# Open the file and split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39f91ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Hoy me voy a comprar un vehÃ­culo, pero no sÃ© cuÃ¡l elegir\n",
      "Me gustan tanto los coches como las motos\n",
      "Sin embargo, las motos son mÃ¡s econÃ³micas que los coches, aunque menos seguras\n",
      "No sÃ© quÃ© hacer\n",
      "Quiero un vehÃ­culo confortable y bonito, Â¡el mÃ¡s bonito de todos!Por la tarde volverÃ© a casa cansado, pero mÃ¡s feliz que por la maÃ±ana\n",
      "AdemÃ¡s, en casa tengo dos animales de compaÃ±Ã­a muy simpÃ¡ticos, aunque poco tranquilos\n",
      "Tengo un perro muy grande y un pÃ¡jaro de color verde\n",
      "El pÃ¡jaro es mucho mÃ¡s pequeÃ±o que el perro\n",
      "Los dos son muy inteligentes y juegan muchÃ­simo entre ellos\n",
      "TodavÃ­a son jÃ³venes, aunque el perro es dos aÃ±os mÃ¡s viejo que el pÃ¡jaro\n",
      "Me encanta ver la televisiÃ³n con ellos para saber quÃ© cosas pasan en el mundo\n",
      "Nos sentamos todos en el sofÃ¡ y somos muy felices.\n"
     ]
    }
   ],
   "source": [
    "file = open( \"C:\\\\Users\\\\varsh\\\\Downloads\\\\Spanish.txt\" , \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d40a40",
   "metadata": {},
   "source": [
    "# Our data: a list of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05bcb7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['ï»¿Hoy', 'me', 'voy', 'a', 'comprar', 'un', 'vehÃ\\xadculo,', 'pero', 'no', 'sÃ©', 'cuÃ¡l', 'elegir'], ['Me', 'gustan', 'tanto', 'los', 'coches', 'como', 'las', 'motos'], ['Sin', 'embargo,', 'las', 'motos', 'son', 'mÃ¡s', 'econÃ³micas', 'que', 'los', 'coches,', 'aunque', 'menos', 'seguras'], ['No', 'sÃ©', 'quÃ©', 'hacer'], ['Quiero', 'un', 'vehÃ\\xadculo', 'confortable', 'y', 'bonito,', 'Â¡el', 'mÃ¡s', 'bonito', 'de', 'todos!Por', 'la', 'tarde', 'volverÃ©', 'a', 'casa', 'cansado,', 'pero', 'mÃ¡s', 'feliz', 'que', 'por', 'la', 'maÃ±ana'], ['AdemÃ¡s,', 'en', 'casa', 'tengo', 'dos', 'animales', 'de', 'compaÃ±Ã\\xada', 'muy', 'simpÃ¡ticos,', 'aunque', 'poco', 'tranquilos'], ['Tengo', 'un', 'perro', 'muy', 'grande', 'y', 'un', 'pÃ¡jaro', 'de', 'color', 'verde'], ['El', 'pÃ¡jaro', 'es', 'mucho', 'mÃ¡s', 'pequeÃ±o', 'que', 'el', 'perro'], ['Los', 'dos', 'son', 'muy', 'inteligentes', 'y', 'juegan', 'muchÃ\\xadsimo', 'entre', 'ellos'], ['TodavÃ\\xada', 'son', 'jÃ³venes,', 'aunque', 'el', 'perro', 'es', 'dos', 'aÃ±os', 'mÃ¡s', 'viejo', 'que', 'el', 'pÃ¡jaro'], ['Me', 'encanta', 'ver', 'la', 'televisiÃ³n', 'con', 'ellos', 'para', 'saber', 'quÃ©', 'cosas', 'pasan', 'en', 'el', 'mundo'], ['Nos', 'sentamos', 'todos', 'en', 'el', 'sofÃ¡', 'y', 'somos', 'muy', 'felices.']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ee6c1a",
   "metadata": {},
   "source": [
    "# Function to calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd064e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity (sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "  # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fe063",
   "metadata": {},
   "source": [
    "# Create the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6564570",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8f32c0",
   "metadata": {},
   "source": [
    "# Similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1 in range(len(sentences)):\n",
    "    for idx2 in range(len(sentences)):\n",
    "        if idx1 == idx2: #ignore if both are same sentences\n",
    "            continue\n",
    "        similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8cc5cf",
   "metadata": {},
   "source": [
    "# Get pagerank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14e6d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c3cfe",
   "metadata": {},
   "source": [
    "# sort sentences by pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba62f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentence = sorted(((scores[i],s) for i,s in\n",
    "enumerate(sentences)), reverse=True)\n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\",\n",
    "ranked_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e51c56",
   "metadata": {},
   "source": [
    "# Pick the top \"n\" sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d582b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 1\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=2\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "    summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816bdeb0",
   "metadata": {},
   "source": [
    "# Finishing off by printing summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c677ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " ï»¿Ogni qual volta disegna suo papÃ  Giuseppe, ad esempio, usa sempre gli stessi colori: i capelli li fa in nero, la maglia Ã¨ azzurra e i pantaloni rigorosamente rossi\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658c23ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
